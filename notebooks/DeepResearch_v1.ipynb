{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Research Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agentic AI Project to replicate OpenAI's Deep Research Agentic AI model. Using this reference primarily to start: https://www.analyticsvidhya.com/blog/2025/02/build-your-own-deep-research-agent/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup / APIs etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Project Root to path to import src files and cofig etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the project root to the Python path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "# Now try importing\n",
    "from src import get_openai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_KEY = get_openai_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tavily API Key - Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import get_tavily_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAVILY_API_KEY = get_tavily_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Agent State Schema - using LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "import operator\n",
    "from typing import Annotated, List, Optional, Literal\n",
    "\n",
    "# defines structure for each section in the report\n",
    "class Section(BaseModel):\n",
    "    name: str = Field(\n",
    "        description=\"Name for a particular section of the report.\",\n",
    "        )\n",
    "    description: str = Field(\n",
    "        description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n",
    "        )\n",
    "    research: bool = Field(\n",
    "        description=\"Whether to perform web search for this section of the report.\"\n",
    "        )\n",
    "    content: str = Field(\n",
    "        description=\"The content for this section.\"\n",
    "        )\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(\n",
    "        description=\"All the Sections of the overall report.\",\n",
    "        )\n",
    "\n",
    "# defines structure for queries generated for deep research\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str = Field(None, description=\"Query for web search.\")\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[SearchQuery] = Field(\n",
    "        description=\"List of web search queries.\",\n",
    "        )\n",
    "\n",
    "# consists of input topic and output report generated\n",
    "class ReportStateInput(TypedDict):\n",
    "    topic: str # Report topic\n",
    "\n",
    "class ReportStateOutput(TypedDict):\n",
    "    final_report: str # Final report\n",
    "\n",
    "# overall agent state which will be passed and updated in nodes in the graph\n",
    "class ReportState(TypedDict):\n",
    "    topic: str # Report topic\n",
    "    sections: list[Section] # List of report sections\n",
    "    completed_sections: Annotated[list, operator.add] # Send() API\n",
    "    report_sections_from_research: str # completed sections to write final sections\n",
    "    final_report: str # Final report\n",
    "\n",
    "# defines the key structure for sections written using the agent \n",
    "class SectionState(TypedDict):\n",
    "    section: Section # Report section\n",
    "    search_queries: list[SearchQuery] # List of search queries\n",
    "    source_str: str # String of formatted source content from web search\n",
    "    report_sections_from_research: str # completed sections to write final sections\n",
    "    completed_sections: list[Section] # Final key in outer state for Send() API\n",
    "\n",
    "class SectionOutputState(TypedDict):\n",
    "    completed_sections: list[Section] # Final key in outer state for Send() API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asynchronous search queries for a list of queries - returning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "import asyncio\n",
    "from dataclasses import asdict, dataclass\n",
    "\n",
    "# just to handle objects created from LLM reponses\n",
    "@dataclass\n",
    "class SearchQuery:\n",
    "    search_query: str\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return asdict(self)\n",
    "\n",
    "tavily_search = TavilySearchAPIWrapper()\n",
    "\n",
    "async def run_search_queries(\n",
    "    search_queries: List[Union[str, SearchQuery]],\n",
    "    num_results: int = 5,\n",
    "    include_raw_content: bool = False\n",
    ") -> List[Dict]:\n",
    "    search_tasks = []\n",
    "    for query in search_queries:\n",
    "        # Handle both string and SearchQuery objects\n",
    "        # Just in case LLM fails to generate queries as:\n",
    "        # class SearchQuery(BaseModel):\n",
    "        #     search_query: str\n",
    "        query_str = query.search_query if isinstance(query, SearchQuery)\n",
    "                        else str(query) # text query\n",
    "        try:\n",
    "            # get results from tavily async (in parallel) for each search query\n",
    "            search_tasks.append(\n",
    "                tavily_search.raw_results_async(\n",
    "                    query=query_str,\n",
    "                    max_results=num_results,\n",
    "                    search_depth='advanced',\n",
    "                    include_answer=False,\n",
    "                    include_raw_content=include_raw_content\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating search task for query '{query_str}': {e}\")\n",
    "            continue\n",
    "    # Execute all searches concurrently and await results\n",
    "    try:\n",
    "        if not search_tasks:\n",
    "            return []\n",
    "        search_docs = await asyncio.gather(*search_tasks, return_exceptions=True)\n",
    "        # Filter out any exceptions from the results\n",
    "        valid_results = [\n",
    "            doc for doc in search_docs\n",
    "            if not isinstance(doc, Exception)\n",
    "        ]\n",
    "        return valid_results\n",
    "    except Exception as e:\n",
    "        print(f\"Error during search queries: {e}\")\n",
    "        return []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepResearchProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
